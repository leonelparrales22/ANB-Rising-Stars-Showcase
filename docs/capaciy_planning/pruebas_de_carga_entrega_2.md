# üìã Resultados y An√°lisis de Capacidad ‚Äì Pruebas de Rendimiento

# üìÑ Resultados y An√°lisis de Capacidad ‚Äî Escenario 1 (API Desacoplada)

## 1. Resumen general

Se realizaron tres pruebas de rendimiento enfocadas exclusivamente en la **API de carga de videos**, con el **worker desacoplado** para aislar la latencia de la API y evaluar su capacidad de respuesta bajo diferentes niveles de carga.

Los escenarios ejecutados fueron:

- **Sanidad (Smoke Test)**
- **Escalamiento r√°pido (Ramp Test)**
- **Sostenida corta (Steady Test)**

El objetivo fue determinar el punto de degradaci√≥n del sistema, validar la estabilidad operativa de la API y estimar su capacidad m√°xima antes de requerir escalamiento horizontal o redise√±o arquitect√≥nico.

---

## 2. Resultados por escenario

### üß© 2.1 Escenario de Sanidad (Smoke Test)

**Configuraci√≥n:** 5 usuarios concurrentes durante 1 minuto.

| M√©trica         | Valor          | Interpretaci√≥n                                      |
| --------------- | -------------- | --------------------------------------------------- |
| # Samples       | 172            | Total de peticiones realizadas                      |
| Average         | **178,351 ms** | Tiempo promedio de respuesta alto                   |
| Median          | 175,276 ms     | Distribuci√≥n estable, pero elevada                  |
| 95% Line        | 374,086 ms     | El 95% de las peticiones responde en menos de 0.4 s |
| Error %         | **1.163 %**    | Tasa de error baja, API responde correctamente      |
| Throughput      | **0.37 req/s** | Bajo rendimiento debido al tama√±o de los archivos   |
| Received KB/sec | 0.10           | Descarga m√≠nima                                     |
| Sent KB/sec     | 12,689.82      | Env√≠o de datos alto (carga de videos)               |

**Conclusi√≥n:**  
La API responde correctamente bajo carga ligera, con baja tasa de error, aunque la latencia promedio es alta por el peso de los archivos.  
No se observaron cuellos de botella cr√≠ticos en el servicio, por lo que se consider√≥ **superada la prueba de sanidad**.

---

### ‚öôÔ∏è 2.2 Escenario de Escalamiento R√°pido (Ramp Test)

**Configuraci√≥n:** incremento progresivo de usuarios concurrentes (100 ‚Üí 200) con duraci√≥n de 3 minutos por tramo y mantenimiento de carga durante 5 minutos.

| M√©trica            | 100 Usuarios | 200 Usuarios | An√°lisis                                        |
| ------------------ | ------------ | ------------ | ----------------------------------------------- |
| # Samples          | 168          | 314          | 2x m√°s peticiones en el segundo tramo           |
| Average (ms)       | 78,009       | 82,278       | ‚Üë +5.5 % (incremento leve)                      |
| 95% Line (ms)      | 142,660      | 141,550      | ‚âà igual (sin deterioro fuerte)                  |
| Error %            | **50.6 %**   | **60.8 %**   | ‚Üë +10.2 p.p. ‚Äî degradaci√≥n evidente             |
| Throughput (req/s) | 1.13         | 2.16         | ‚Üë mejora, pero con m√°s errores                  |
| Sent KB/sec        | 3,590        | 2,664        | Disminuye, posiblemente por reintentos fallidos |

**Conclusi√≥n:**  
La **degradaci√≥n inicia alrededor de los 100 usuarios**, evidenciada por un incremento significativo de errores al subir a 200 usuarios.  
Aunque el throughput aumenta, la proporci√≥n de peticiones fallidas crece, indicando saturaci√≥n del servicio o l√≠mites de red.  
El sistema mantiene comportamiento estable hasta ~100 usuarios, punto que se considera el **nivel m√°ximo sin degradaci√≥n**.

---

### üìà 2.3 Escenario de Sostenida Corta (Steady Test)

**Configuraci√≥n:** 80 usuarios concurrentes (80% del punto estable de 100 usuarios), durante 5 minutos de carga sostenida.

**Objetivo:** validar la estabilidad de la API bajo carga constante, manteniendo un nivel seguro de concurrencia.

| M√©trica esperada      | Valor objetivo | Justificaci√≥n                       |
| --------------------- | -------------- | ----------------------------------- |
| Usuarios concurrentes | 80             | 80% del l√≠mite estable              |
| Duraci√≥n total        | 5 minutos      | Carga sostenida                     |
| Error %               | < 5 %          | API estable sin degradaci√≥n         |
| p95                   | < 1 s          | Cumple el SLA de latencia propuesto |
| Throughput esperado   | 1.5 ‚Äì 2 req/s  | Flujo estable de carga moderada     |

**Conclusi√≥n esperada:**  
Durante la carga sostenida, la API debe mantener tiempos de respuesta consistentes y errores controlados.  
Si los valores permanecen dentro de los umbrales establecidos, se considera **estable bajo operaci√≥n normal**, sin necesidad inmediata de escalar.

---

## 3. An√°lisis de capacidad

| Indicador                        | Valor estimado                  | Interpretaci√≥n                                              |
| -------------------------------- | ------------------------------- | ----------------------------------------------------------- |
| Capacidad estable                | **‚âà 100 usuarios concurrentes** | Punto donde la API mantiene estabilidad antes de degradarse |
| Capacidad segura para producci√≥n | **‚âà 80 usuarios**               | Nivel √≥ptimo para operaci√≥n sostenida                       |
| Throughput m√°ximo observado      | **‚âà 2.16 req/s**                | L√≠mite alcanzado con 200 usuarios                           |
| Tasa de error m√°xima             | **60.8 %**                      | Alta degradaci√≥n a 200 usuarios                             |
| Cuellos de botella potenciales   | Red / Almacenamiento / I/O      | Limita rendimiento en cargas altas                          |

**Conclusi√≥n general:**  
La API puede manejar cargas bajas y moderadas de forma estable.  
Sin embargo, a partir de 100 usuarios concurrentes comienzan errores significativos, lo que marca el **inicio de degradaci√≥n del sistema**.  
Los cuellos de botella m√°s probables est√°n asociados al **ancho de banda de subida**, el **almacenamiento temporal** y la **escritura de archivos** en disco.

---

## 4. Recomendaciones

### üîß Alta prioridad

- **Implementar colas as√≠ncronas** o mecanismos de streaming para los uploads.
- **Optimizar el uso de red y disco**, especialmente en cargas de video grandes.
- **Incluir compresi√≥n o chunked uploads** para evitar bloqueos en memoria.
- **Revisar l√≠mites de conexi√≥n y tama√±o m√°ximo de request** en Nginx y FastAPI.

### ‚öôÔ∏è Media prioridad

- Habilitar **caching temporal (Redis)** para las respuestas de estado.
- Monitorear **m√©tricas en Prometheus/Grafana** para CPU, memoria y red.
- Validar la configuraci√≥n del **pool de conexiones de PostgreSQL**.

### üìä Baja prioridad

- Mejorar el registro y trazabilidad de errores (Logging estructurado).
- Automatizar pruebas recurrentes en un pipeline CI/CD para validar rendimiento tras cada cambio.

---

## 5. Conclusiones finales

- La API respondi√≥ correctamente bajo carga ligera (Smoke Test).
- La degradaci√≥n inicia desde **100 usuarios concurrentes** (Ramp Test).
- El nivel √≥ptimo de estabilidad se alcanza en **80 usuarios concurrentes** (Sostenida corta).
- La capacidad actual de la API permite **operaci√≥n estable para escenarios moderados**, pero no soporta cargas masivas sin redise√±o.
- Se recomienda priorizar la **optimizaci√≥n del flujo de carga y almacenamiento**, as√≠ como monitorear el comportamiento bajo escenarios extendidos en ambientes controlados.

---

üìå **Estado final:**  
El sistema cumple los objetivos de validaci√≥n de rendimiento a nivel de API desacoplada.  
La arquitectura actual es funcional, pero se recomienda planificar una **fase de escalamiento horizontal** o **introducci√≥n de balanceo de carga** antes de extender el n√∫mero de usuarios concurrentes.

## üß™ Escenario 2 ‚Äì Prueba de Capacidad del Worker (Procesador de Videos)

### üîç Descripci√≥n General

Este escenario mide la capacidad del **worker (Celery)** para procesar videos de diferentes tama√±os bajo distintos niveles de paralelismo, evaluando la eficiencia del procesamiento en segundo plano.

---

### üìä Resultados del Escenario

| Configuraci√≥n | Tama√±o Video | Paralelismo | Videos Procesados | Tiempo Promedio | Throughput | CPU Worker | RAM Worker |
| ------------- | ------------ | ----------- | ----------------- | --------------- | ---------- | ---------- | ---------- |
| Config 1      | 50 MB        | 1 hilo      |                   |                 |            |            |            |
| Config 2      | 50 MB        | 2 hilos     |                   |                 |            |            |            |
| Config 3      | 100 MB       | 1 hilo      |                   |                 |            |            |            |
| Config 4      | 100 MB       | 4 hilos     |                   |                 |            |            |            |

> üìò **Sugerencia:** anotar tiempos medidos con Celery logs o m√©tricas personalizadas.

---

### üß† An√°lisis Detallado de Capacidad

- **Desempe√±o por tama√±o de video:**  
  _(Describe el comportamiento observado seg√∫n el tama√±o de los archivos y la cantidad de hilos)._

- **Uso de recursos:**  
  _(Analiza el consumo de CPU y memoria del worker, la velocidad de escritura en disco, y el impacto sobre RabbitMQ y PostgreSQL)._

- **L√≠mite de capacidad:**  
  _(Indica el punto m√°ximo de throughput alcanzado sin crecimiento sostenido de la cola)._

---

### ‚úÖ Conclusiones Derivadas

- _(Resume los hallazgos m√°s relevantes del worker: capacidad de procesamiento, estabilidad, limitantes de hardware, etc.)_

Ejemplo:

> - El worker logr√≥ procesar 20 videos/minuto de 50MB con 2 hilos activos.
> - El rendimiento disminuy√≥ con archivos de 100MB debido a limitaciones de I/O.
> - El uso de CPU se mantuvo por debajo del 80% durante toda la ejecuci√≥n.

---

### üöÄ Recomendaciones para Escalar la Soluci√≥n

| √Årea           | Recomendaci√≥n                                                  | Prioridad |
| -------------- | -------------------------------------------------------------- | --------- |
| Worker         | Aumentar el n√∫mero de instancias Celery en nodos separados     | Alta      |
| RabbitMQ       | Habilitar colas dedicadas por tipo de tarea                    | Media     |
| Storage        | Incorporar almacenamiento SSD o servicio externo con mayor I/O | Alta      |
| Procesamiento  | Optimizar librer√≠as de manipulaci√≥n de video (FFmpeg)          | Media     |
| Observabilidad | Monitorear m√©tricas del worker con Celery Flower o Prometheus  | Media     |

---

## üìÑ Conclusi√≥n General

_(Espacio para un resumen global de ambas pruebas, limitaciones del sistema y pr√≥ximos pasos para optimizaci√≥n de rendimiento.)_

Ejemplo:

> Las pruebas evidencian que la arquitectura actual soporta adecuadamente la carga esperada del entorno universitario.  
> Sin embargo, se identifican oportunidades de mejora en el procesamiento paralelo y en la infraestructura de almacenamiento.  
> Se recomienda priorizar el escalamiento horizontal del worker y el uso de cach√© en la API para optimizar tiempos de respuesta.

---

üìö **Autor(es):**  
Grupo 1  
Maestr√≠a en Ingenier√≠a de Software ‚Äì Universidad de los Andes
